{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_Portuguese - English.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hWaEWxsbjf"
      },
      "source": [
        "### NMT (Nueral Machine Translation)\n",
        "\n",
        "In these series of notebooks we are going to do create bidirectional NMT model for our application. We are going to use the following notebooks as reference to this notebook.\n",
        "\n",
        "1. [17_Custom_Dataset_and_Translation.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/17_Custom_Dataset_and_Translation.ipynb)\n",
        "2. [16_Data_Preparation_Translation_Dataset.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/16_Data_Preparation_Translation_Dataset.ipynb)\n",
        "3. [07_Attention_is_all_you_need](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/07_Attention_is_all_you_need.ipynb)\n",
        "\n",
        "I will be loading the data from my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEY0_2fdsbLZ",
        "outputId": "f8288925-7ef2-4efa-f5db-868f5dea3492"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61k3sTWuGYt"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNfuXwhsbFx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn  import functional as F\n",
        "import spacy, math, random\n",
        "import numpy as np\n",
        "from torchtext.legacy import datasets, data\n",
        "import time, os, json\n",
        "from prettytable import PrettyTable\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nOk8n7sbCx"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjqtcpj8uZsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a87b7b2-8b46-4ea7-e6ff-e2fcb995f61b"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKiHZEUKuR2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57761f64-d3a3-4098-ec44-160739511264"
      },
      "source": [
        "base_path = '/content/drive/My Drive/NLP Data/seq2seq/manythings'\n",
        "path_to_files = os.path.join(base_path, \"Portuguese - English\")\n",
        "os.listdir(path_to_files)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['por.txt',\n",
              " 'valid.en',\n",
              " 'test.en',\n",
              " 'test.po',\n",
              " 'valid.po',\n",
              " 'train.en',\n",
              " 'train.po']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga_vPyt3u5IE"
      },
      "source": [
        "### File extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XV9PLt7uRyI"
      },
      "source": [
        "exts = (\".po\", \".en\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMXQVQAZvB60"
      },
      "source": [
        "### Tokenizer models\n",
        "\n",
        "All the tokenization models that we are going to use are going to be found [here](https://spacy.io/usage/models) but to those languages that doesn't have tokenization models we are going to create our own tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drvBIe75uRwR",
        "outputId": "e4a577ee-971f-4f3b-f747-baf656010e3d"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download(\"pt_core_news_sm\")\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "spacy_pt = spacy.load('pt_core_news_sm')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2PFvU6uRsm"
      },
      "source": [
        "def tokenize_pt(sent):\n",
        "  return [tok.text for tok in spacy_pt.tokenizer(sent)]\n",
        "\n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmCTTn4Hwiom"
      },
      "source": [
        "### Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8oJesouRqO"
      },
      "source": [
        "SRC = data.Field(\n",
        "    tokenize = tokenize_pt,\n",
        "    lower= True,\n",
        "    init_token = \"<sos>\",\n",
        "     eos_token = \"<eos>\",\n",
        "     include_lengths =True\n",
        ")\n",
        "TRG = data.Field(\n",
        "    tokenize = tokenize_en,\n",
        "    lower= True,\n",
        "    init_token = \"<sos>\",\n",
        "     eos_token = \"<eos>\"\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWi2bUtHw4_e"
      },
      "source": [
        "### Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "natPw3mhuRnQ"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.TranslationDataset.splits(\n",
        "    exts= exts,\n",
        "    path=path_to_files,\n",
        "    train='train', validation='valid', test='test',\n",
        "    fields = (SRC, TRG)\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-04eSK8uRkp",
        "outputId": "70bc0110-3e84-4bed-8056-e236d6f0ef5f"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['algumas', 'pessoas', 'gostam', '.'], 'trg': ['some', 'people', 'like', 'it', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEHHOMmDxKlO",
        "outputId": "d95e36c6-30d6-4289-8688-6fae8a55f376"
      },
      "source": [
        "print(vars(valid_data.examples[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['tenho', 'que', 'partir', 'agora', '.'], 'trg': ['i', 'have', 'to', 'leave', 'now', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxM9sZGfuRhx",
        "outputId": "f9230f24-ac95-4893-9c1a-ab58174699f5"
      },
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['tom', 'parece', 'aliviado', '.'], 'trg': ['tom', 'looks', 'relieved', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAV3a9mPxOss"
      },
      "source": [
        "### Counting examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyEk_Y01uRen",
        "outputId": "43ca2e3d-8701-46ac-a3ee-238a0c78fbef"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= \"VISUALIZING SETS EXAMPLES\"\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "column_names = [\"SUBSET\", \"EXAMPLE(s)\"]\n",
        "row_data = [\n",
        "        [\"training\", len(train_data)],\n",
        "        ['validation', len(valid_data)],\n",
        "        ['test', len(test_data)]\n",
        "]\n",
        "tabulate(column_names, row_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|  VISUALIZING SETS EXAMPLES  |\n",
            "+--------------+--------------+\n",
            "| SUBSET       |   EXAMPLE(s) |\n",
            "+--------------+--------------+\n",
            "| training     |       174203 |\n",
            "| validation   |         1760 |\n",
            "| test         |         1778 |\n",
            "+--------------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljHsxO81xVdn"
      },
      "source": [
        "Our dataset is very small so we are not going to set the `min_freq` to a number greater than 1 dring building of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmv9XL9EuRcN"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7oilFldx-X9"
      },
      "source": [
        "Saving the dictionary maping of our SRC and TRG to a json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA_gPfD2uRZb",
        "outputId": "28477f45-f99c-4cb8-934d-b879045d2f0a"
      },
      "source": [
        "len(SRC.vocab.stoi), len(TRG.vocab.stoi)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14073, 8799)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceitelKvuRWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66097f93-262b-497b-9197-2ba9368c10a3"
      },
      "source": [
        "src = dict(SRC.vocab.stoi)\n",
        "trg = dict(TRG.vocab.stoi)\n",
        "\n",
        "src_vocab_path = \"src_vocab.json\"\n",
        "trg_vocab_path = \"trg_vocab.json\"\n",
        "\n",
        "with open(src_vocab_path, \"w\") as f:\n",
        "  json.dump(src, f, indent=2)\n",
        "\n",
        "with open(trg_vocab_path, \"w\") as f:\n",
        "  json.dump(trg, f, indent=2)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0l5cL4uRTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8a825de3-7c51-4fab-d6e9-d07a09e11ca0"
      },
      "source": [
        "files.download(src_vocab_path)\n",
        "files.download(trg_vocab_path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_dd56536a-4dfa-4ff5-9fdf-0498d9c908a0\", \"src_vocab.json\", 291285)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_240fa213-3b7f-46c4-ac35-37c1acebbd66\", \"trg_vocab.json\", 164631)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6pZxDwzQAT"
      },
      "source": [
        "### Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTE-gGpHuQRH"
      },
      "source": [
        "BATCH_SIZE = 128 # 128 for languages with good vocab corpus\n",
        "sort_key = lambda x: len(x.src)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key= sort_key,\n",
        "    sort_within_batch = True\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY4p8X1Bzrrv"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TstLLxavsbAQ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim=emb_dim)\n",
        "    self.gru = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src, src_len):\n",
        "    embedded = self.dropout(self.embedding(src)) # embedded = [src len, batch size, emb dim]\n",
        "    # need to explicitly put lengths on cpu!\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
        "    packed_outputs, hidden = self.gru(packed_embedded)\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "    return outputs, hidden"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKNRHQS04CG"
      },
      "source": [
        "### Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDr-sIsW06HO"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "    self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs, mask):\n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    # repeat decoder hidden state src_len times\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) # energy = [batch size, src len, dec hid dim]\n",
        "    attention = self.v(energy).squeeze(2) # attention= [batch size, src len]\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "    return F.softmax(attention, dim=1)\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7NlD1sz1BSi"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHiBnQaF1AtW"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.attention = attention\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "    self.gru = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.fc = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "  def forward(self, input, hidden, encoder_outputs, mask):\n",
        "    input = input.unsqueeze(0) # input = [1, batch size]\n",
        "    embedded = self.dropout(self.embedding(input)) # embedded = [1, batch size, emb dim]\n",
        "    a = self.attention(hidden, encoder_outputs, mask)# a = [batch size, src len]\n",
        "    a = a.unsqueeze(1) # a = [batch size, 1, src len]\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2) # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "    weighted = torch.bmm(a, encoder_outputs) # weighted = [batch size, 1, enc hid dim * 2]\n",
        "    weighted = weighted.permute(1, 0, 2) # weighted = [1, batch size, enc hid dim * 2]\n",
        "    rnn_input = torch.cat((embedded, weighted), dim = 2) # rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "    output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "    \n",
        "    assert (output == hidden).all()\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "\n",
        "    prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1)) # prediction = [batch size, output dim]\n",
        "    return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRi_d5xy1LPM"
      },
      "source": [
        "### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMyUUMnr1K0I"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "  \n",
        "  def create_mask(self, src):\n",
        "    mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "    return mask\n",
        "  def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "    \"\"\"\n",
        "    src = [src len, batch size]\n",
        "    src_len = [batch size]\n",
        "    trg = [trg len, batch size]\n",
        "    teacher_forcing_ratio is probability to use teacher forcing\n",
        "    e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "    \"\"\"\n",
        "    trg_len, batch_size = trg.shape\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "    # tensor to store decoder outputs\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "    \"\"\"\n",
        "    encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "    hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "    \"\"\"\n",
        "    encoder_outputs, hidden = self.encoder(src, src_len)     \n",
        "    # first input to the decoder is the <sos> tokens\n",
        "    input = trg[0,:]\n",
        "    mask = self.create_mask(src) # mask = [batch size, src len]\n",
        "    for t in range(1, trg_len):\n",
        "      # insert input token embedding, previous hidden state and all encoder hidden states and mask\n",
        "      # receive output tensor (predictions) and new hidden state\n",
        "      output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "      \n",
        "      # place predictions in a tensor holding predictions for each token\n",
        "      outputs[t] = output\n",
        "      \n",
        "      # decide if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      \n",
        "      # get the highest predicted token from our predictions\n",
        "      top1 = output.argmax(1) \n",
        "      \n",
        "      # if teacher forcing, use actual next token as next input\n",
        "      # if not, use predicted token\n",
        "      input = trg[t] if teacher_force else top1\n",
        "    return outputs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6RraZNi1tS0"
      },
      "source": [
        "### Seq2Seq model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUEfOF60sa6s",
        "outputId": "1902a6ac-f7e7-4fb3-e5c3-2224362d051c"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = DEC_HID_DIM = 128\n",
        "ENC_DROPOUT = DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14073, 256)\n",
              "    (gru): GRU(256, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(8799, 256)\n",
              "    (gru): GRU(512, 128)\n",
              "    (fc): Linear(in_features=640, out_features=8799, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N44tQz5V2CIK"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdNL1peTsa0s",
        "outputId": "8ef99fac-94dd-4808-bbd0-d83a9cf67104"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 12,120,671\n",
            "Total tainable parameters: 12,120,671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yld0SPhi2HUm"
      },
      "source": [
        "Initialize model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JDmgtkGsav_",
        "outputId": "40f8326d-9154-4f7b-a5aa-3b8fac1aadb4"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "        nn.init.constant_(param.data, 0)   \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14073, 256)\n",
              "    (gru): GRU(256, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(8799, 256)\n",
              "    (gru): GRU(512, 128)\n",
              "    (fc): Linear(in_features=640, out_features=8799, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1OnvuMKBIg_"
      },
      "source": [
        "### Optimizer and Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PowuX5bsasj"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX).to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpNeWJEJ2pcN"
      },
      "source": [
        "### Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVjp9XOsamS"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, src_len = batch.src\n",
        "        src = src.to(device)\n",
        "        src_len = src_len.to(device)\n",
        "        trg = batch.trg\n",
        "        trg = trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_len, trg)\n",
        "        \"\"\"\n",
        "        trg = [trg len, batch size]\n",
        "        output = [trg len, batch size, output dim]\n",
        "        \"\"\"\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \"\"\"\n",
        "        trg = [(trg len - 1) * batch size]\n",
        "        output = [(trg len - 1) * batch size, output dim]\n",
        "        \"\"\"\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for i, batch in enumerate(iterator):\n",
        "          src, src_len = batch.src\n",
        "          src = src.to(device)\n",
        "          src_len = src_len.to(device)\n",
        "          trg = batch.trg\n",
        "          trg = trg.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(src, src_len, trg, 0) ## Turn off the teacher forcing ratio.\n",
        "          \"\"\"\n",
        "          trg = [trg len, batch size]\n",
        "          output = [trg len, batch size, output dim]\n",
        "          \"\"\"\n",
        "          output_dim = output.shape[-1]\n",
        "          output = output[1:].view(-1, output_dim)\n",
        "          trg = trg[1:].view(-1)\n",
        "          \"\"\"\n",
        "          trg = [(trg len - 1) * batch size]\n",
        "          output = [(trg len - 1) * batch size, output dim]\n",
        "          \"\"\"\n",
        "          loss =  criterion(output, trg)\n",
        "          epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQG1RgUi2ujL"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z8_TXq8sadI"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def tabulate_training(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  table.align[column_names[2]] = 'r'\n",
        "  table.align[column_names[3]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhkS-JDd35qx"
      },
      "source": [
        "### Model Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCDVLXV39iK"
      },
      "source": [
        "MODEL_NAME = \"eng-po.pt\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shJMTRS7saRC",
        "outputId": "3936f8a0-1754-4ec2-b894-8b146aa846d1"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "column_names = [\"SET\", \"LOSS\", \"PPL\", \"ETA\"]\n",
        "print(\"TRAINING START....\")\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "  end = time.time()\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} | {'saving model...' if valid_loss < best_valid_loss else 'not saving...'}\" \n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), MODEL_NAME)\n",
        "  rows_data =[\n",
        "        [\"train\", f\"{train_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", hms_string(end - start) ],\n",
        "        [\"val\", f\"{valid_loss:.3f}\", f\"{math.exp(valid_loss):7.3f}\", '' ]\n",
        "  ]\n",
        "  tabulate_training(column_names, rows_data, title)\n",
        "\n",
        "print(\"TRAINING ENDS....\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING START....\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 01/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.643 |  38.225 | 0:03:08.17 |\n",
            "| val   | 2.721 |  38.225 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 02/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.873 |   6.507 | 0:03:06.42 |\n",
            "| val   | 2.014 |   6.507 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 03/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.372 |   3.942 | 0:03:07.45 |\n",
            "| val   | 1.756 |   3.942 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 04/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.156 |   3.176 | 0:03:07.20 |\n",
            "| val   | 1.637 |   3.176 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 05/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.027 |   2.793 | 0:03:07.43 |\n",
            "| val   | 1.614 |   2.793 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 06/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 0.938 |   2.555 | 0:03:07.24 |\n",
            "| val   | 1.598 |   2.555 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 07/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 0.872 |   2.392 | 0:03:08.70 |\n",
            "| val   | 1.562 |   2.392 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 08/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 0.828 |   2.288 | 0:03:08.71 |\n",
            "| val   | 1.530 |   2.288 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 09/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 0.787 |   2.197 | 0:03:08.65 |\n",
            "| val   | 1.499 |   2.197 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 10/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 0.765 |   2.150 | 0:03:09.06 |\n",
            "| val   | 1.548 |   2.150 |            |\n",
            "+-------+-------+---------+------------+\n",
            "TRAINING ENDS....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1_A2Nz5sKJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd8af0a-c8ee-4c48-f1ae-c66e68cc0f81"
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_NAME))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{math.exp(test_loss):7.3f}', \"\"]]\n",
        "\n",
        "tabulate_training([\"SET\", \"LOSS\", \"PPL\", \"ETA\"], data_rows, title)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|   Model Evaluation Summary   |\n",
            "+------+-------+---------+-----+\n",
            "| SET  |  LOSS |     PPL | ETA |\n",
            "+------+-------+---------+-----+\n",
            "| Test | 1.475 |   4.371 |     |\n",
            "+------+-------+---------+-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J9H6zur4WU0"
      },
      "source": [
        "### Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duN_U05sBlkx"
      },
      "source": [
        "import pt_core_news_sm\n",
        "nlp = pt_core_news_sm.load()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPwMVJZ14Sxr"
      },
      "source": [
        "def translate_sentence(sent, src_field, trg_field, mdoel, device, max_len=50):\n",
        "  model.eval()\n",
        "\n",
        "  if isinstance(sent, str):\n",
        "    tokens = [token.text.lower() for token in nlp(sent)]\n",
        "  else:\n",
        "    tokens = [token.lower() for token in sent]\n",
        "  \n",
        "  tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "  src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "  src_len = torch.LongTensor([len(src_indexes)])\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "  mask = model.create_mask(src_tensor)\n",
        "  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "    with torch.no_grad():\n",
        "      output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "    attentions[i] = attention\n",
        "    pred_token = output.argmax(1).item()\n",
        "    trg_indexes.append(pred_token)\n",
        "\n",
        "    if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "       break\n",
        "  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "  return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqGmZM3q4uRG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPjW60N4ve_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ca5303-23f4-42a8-c737-9472301855f3"
      },
      "source": [
        "example_idx = 6\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['tom', 'não', 'percebeu', 'a', 'mudança', '.']\n",
            "trg = ['tom', 'did', \"n't\", 'notice', 'the', 'change', '.']\n",
            "predicted trg = ['tom', 'did', \"n't\", 'notice', 'the', 'change', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnwUFJB4B4Aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161dbfc4-ed38-4381-b43a-01b9621c0a3d"
      },
      "source": [
        "example_idx = 0\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "tokens, attention = translate_sentence(src,  SRC, TRG, model, device)\n",
        "print(f'pred = {tokens}')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['algumas', 'pessoas', 'gostam', '.']\n",
            "trg = ['some', 'people', 'like', 'it', '.']\n",
            "pred = ['some', 'people', 'like', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IbwtKGXQRQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef188db-2205-4832-9e8f-a8f38ab40780"
      },
      "source": [
        "example_idx = 0\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "tokens, attention = translate_sentence(src,  SRC, TRG, model, device)\n",
        "print(f'pred = {tokens}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['tom', 'parece', 'aliviado', '.']\n",
            "trg = ['tom', 'looks', 'relieved', '.']\n",
            "pred = ['tom', 'seems', 'relieved', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndxi8HR5QH_"
      },
      "source": [
        "Downloading the model name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47bvlKVO43k6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9ef1afb1-87e9-44d1-e7c6-50949985b8c4"
      },
      "source": [
        "files.download(MODEL_NAME)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d99bd79c-9047-4787-a0a9-d330bc629a22\", \"eng-po.pt\", 48487108)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_0KD0l1OM34"
      },
      "source": [
        "### BLEU SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qF2GsD85SM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c496c5-f262-4c5c-c94a-2ea81b03ed23"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    for datum in data:\n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        # cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "\n",
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 58.23\n"
          ]
        }
      ]
    }
  ]
}