{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02_English - Portuguese.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hWaEWxsbjf"
      },
      "source": [
        "### NMT (Nueral Machine Translation)\n",
        "\n",
        "In these series of notebooks we are going to do create bidirectional NMT model for our application. We are going to use the following notebooks as reference to this notebook.\n",
        "\n",
        "1. [17_Custom_Dataset_and_Translation.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/17_Custom_Dataset_and_Translation.ipynb)\n",
        "2. [16_Data_Preparation_Translation_Dataset.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/16_Data_Preparation_Translation_Dataset.ipynb)\n",
        "3. [07_Attention_is_all_you_need](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/07_Attention_is_all_you_need.ipynb)\n",
        "\n",
        "I will be loading the data from my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEY0_2fdsbLZ",
        "outputId": "936fcb60-a078-45c3-d2e1-c52624ded156"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61k3sTWuGYt"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNfuXwhsbFx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn  import functional as F\n",
        "import spacy, math, random\n",
        "import numpy as np\n",
        "from torchtext.legacy import datasets, data\n",
        "import time, os, json\n",
        "from prettytable import PrettyTable\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nOk8n7sbCx"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjqtcpj8uZsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd43d130-1705-4d14-d1e2-442376404458"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKiHZEUKuR2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95882346-52c9-470f-b162-944f2122a197"
      },
      "source": [
        "base_path = '/content/drive/My Drive/NLP Data/seq2seq/manythings'\n",
        "path_to_files = os.path.join(base_path, \"Portuguese - English\")\n",
        "os.listdir(path_to_files)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['por.txt',\n",
              " 'valid.en',\n",
              " 'test.en',\n",
              " 'test.po',\n",
              " 'valid.po',\n",
              " 'train.en',\n",
              " 'train.po']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga_vPyt3u5IE"
      },
      "source": [
        "### File extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XV9PLt7uRyI"
      },
      "source": [
        "exts = (\".en\", \".po\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMXQVQAZvB60"
      },
      "source": [
        "### Tokenizer models\n",
        "\n",
        "All the tokenization models that we are going to use are going to be found [here](https://spacy.io/usage/models) but to those languages that doesn't have tokenization models we are going to create our own tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drvBIe75uRwR",
        "outputId": "f6f004f9-ddbd-448c-a2d5-cd4150bfa34e"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download(\"pt_core_news_sm\")\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "spacy_pt = spacy.load('pt_core_news_sm')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2PFvU6uRsm"
      },
      "source": [
        "def tokenize_pt(sent):\n",
        "  return [tok.text for tok in spacy_pt.tokenizer(sent)]\n",
        "\n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmCTTn4Hwiom"
      },
      "source": [
        "### Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8oJesouRqO"
      },
      "source": [
        "SRC = data.Field(\n",
        "    tokenize = tokenize_en,\n",
        "    lower= True,\n",
        "    init_token = \"<sos>\",\n",
        "     eos_token = \"<eos>\",\n",
        "     include_lengths =True\n",
        ")\n",
        "TRG = data.Field(\n",
        "    tokenize = tokenize_pt,\n",
        "    lower= True,\n",
        "    init_token = \"<sos>\",\n",
        "     eos_token = \"<eos>\"\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWi2bUtHw4_e"
      },
      "source": [
        "### Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "natPw3mhuRnQ"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.TranslationDataset.splits(\n",
        "    exts= exts,\n",
        "    path=path_to_files,\n",
        "    train='train', validation='valid', test='test',\n",
        "    fields = (SRC, TRG)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-04eSK8uRkp",
        "outputId": "78bbe057-86b6-4b04-8dd5-66b11b301f0e"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['some', 'people', 'like', 'it', '.'], 'trg': ['algumas', 'pessoas', 'gostam', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEHHOMmDxKlO",
        "outputId": "a07902ae-a204-4de8-ae8d-2114e0faf482"
      },
      "source": [
        "print(vars(valid_data.examples[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['i', 'have', 'to', 'leave', 'now', '.'], 'trg': ['tenho', 'que', 'partir', 'agora', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxM9sZGfuRhx",
        "outputId": "b3059c5a-c08d-4817-8e30-29e8f3c91fc9"
      },
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['tom', 'looks', 'relieved', '.'], 'trg': ['tom', 'parece', 'aliviado', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAV3a9mPxOss"
      },
      "source": [
        "### Counting examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyEk_Y01uRen",
        "outputId": "3bbde711-335c-4794-a9f1-52be7c9fdaa4"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= \"VISUALIZING SETS EXAMPLES\"\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "column_names = [\"SUBSET\", \"EXAMPLE(s)\"]\n",
        "row_data = [\n",
        "        [\"training\", len(train_data)],\n",
        "        ['validation', len(valid_data)],\n",
        "        ['test', len(test_data)]\n",
        "]\n",
        "tabulate(column_names, row_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|  VISUALIZING SETS EXAMPLES  |\n",
            "+--------------+--------------+\n",
            "| SUBSET       |   EXAMPLE(s) |\n",
            "+--------------+--------------+\n",
            "| training     |       174203 |\n",
            "| validation   |         1760 |\n",
            "| test         |         1778 |\n",
            "+--------------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljHsxO81xVdn"
      },
      "source": [
        "Our dataset is very small so we are not going to set the `min_freq` to a number greater than 1 dring building of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmv9XL9EuRcN"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7oilFldx-X9"
      },
      "source": [
        "Saving the dictionary maping of our SRC and TRG to a json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA_gPfD2uRZb",
        "outputId": "8b2cf262-b407-4f63-8446-2236faafb912"
      },
      "source": [
        "len(SRC.vocab.stoi), len(TRG.vocab.stoi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8799, 14073)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceitelKvuRWX"
      },
      "source": [
        "# src = dict(SRC.vocab.stoi)\n",
        "# trg = dict(TRG.vocab.stoi)\n",
        "\n",
        "# src_vocab_path = \"src_vocab.json\"\n",
        "# trg_vocab_path = \"trg_vocab.json\"\n",
        "\n",
        "# with open(src_vocab_path, \"w\") as f:\n",
        "#   json.dump(src, f, indent=2)\n",
        "\n",
        "# with open(trg_vocab_path, \"w\") as f:\n",
        "#   json.dump(trg, f, indent=2)\n",
        "\n",
        "# print(\"Done\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0l5cL4uRTO"
      },
      "source": [
        "# files.download(src_vocab_path)\n",
        "# files.download(trg_vocab_path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6pZxDwzQAT"
      },
      "source": [
        "### Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTE-gGpHuQRH"
      },
      "source": [
        "BATCH_SIZE = 128 # 128 for languages with good vocab corpus\n",
        "sort_key = lambda x: len(x.src)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key= sort_key,\n",
        "    sort_within_batch = True\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY4p8X1Bzrrv"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TstLLxavsbAQ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim=emb_dim)\n",
        "    self.gru = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src, src_len):\n",
        "    embedded = self.dropout(self.embedding(src)) # embedded = [src len, batch size, emb dim]\n",
        "    # need to explicitly put lengths on cpu!\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
        "    packed_outputs, hidden = self.gru(packed_embedded)\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "    return outputs, hidden"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKNRHQS04CG"
      },
      "source": [
        "### Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDr-sIsW06HO"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "    self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs, mask):\n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    # repeat decoder hidden state src_len times\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) # energy = [batch size, src len, dec hid dim]\n",
        "    attention = self.v(energy).squeeze(2) # attention= [batch size, src len]\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "    return F.softmax(attention, dim=1)\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7NlD1sz1BSi"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHiBnQaF1AtW"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.attention = attention\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "    self.gru = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.fc = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "  def forward(self, input, hidden, encoder_outputs, mask):\n",
        "    input = input.unsqueeze(0) # input = [1, batch size]\n",
        "    embedded = self.dropout(self.embedding(input)) # embedded = [1, batch size, emb dim]\n",
        "    a = self.attention(hidden, encoder_outputs, mask)# a = [batch size, src len]\n",
        "    a = a.unsqueeze(1) # a = [batch size, 1, src len]\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2) # encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "    weighted = torch.bmm(a, encoder_outputs) # weighted = [batch size, 1, enc hid dim * 2]\n",
        "    weighted = weighted.permute(1, 0, 2) # weighted = [1, batch size, enc hid dim * 2]\n",
        "    rnn_input = torch.cat((embedded, weighted), dim = 2) # rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "    output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "    \n",
        "    assert (output == hidden).all()\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "\n",
        "    prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1)) # prediction = [batch size, output dim]\n",
        "    return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRi_d5xy1LPM"
      },
      "source": [
        "### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMyUUMnr1K0I"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "  \n",
        "  def create_mask(self, src):\n",
        "    mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "    return mask\n",
        "  def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "    \"\"\"\n",
        "    src = [src len, batch size]\n",
        "    src_len = [batch size]\n",
        "    trg = [trg len, batch size]\n",
        "    teacher_forcing_ratio is probability to use teacher forcing\n",
        "    e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "    \"\"\"\n",
        "    trg_len, batch_size = trg.shape\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "    # tensor to store decoder outputs\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "    \"\"\"\n",
        "    encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "    hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "    \"\"\"\n",
        "    encoder_outputs, hidden = self.encoder(src, src_len)     \n",
        "    # first input to the decoder is the <sos> tokens\n",
        "    input = trg[0,:]\n",
        "    mask = self.create_mask(src) # mask = [batch size, src len]\n",
        "    for t in range(1, trg_len):\n",
        "      # insert input token embedding, previous hidden state and all encoder hidden states and mask\n",
        "      # receive output tensor (predictions) and new hidden state\n",
        "      output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "      \n",
        "      # place predictions in a tensor holding predictions for each token\n",
        "      outputs[t] = output\n",
        "      \n",
        "      # decide if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      \n",
        "      # get the highest predicted token from our predictions\n",
        "      top1 = output.argmax(1) \n",
        "      \n",
        "      # if teacher forcing, use actual next token as next input\n",
        "      # if not, use predicted token\n",
        "      input = trg[t] if teacher_force else top1\n",
        "    return outputs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6RraZNi1tS0"
      },
      "source": [
        "### Seq2Seq model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUEfOF60sa6s",
        "outputId": "39e73a20-32a9-49c1-c4d1-a436e0d079fe"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = DEC_HID_DIM = 128\n",
        "ENC_DROPOUT = DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(8799, 256)\n",
              "    (gru): GRU(256, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(14073, 256)\n",
              "    (gru): GRU(512, 128)\n",
              "    (fc): Linear(in_features=640, out_features=14073, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N44tQz5V2CIK"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdNL1peTsa0s",
        "outputId": "8f02fbeb-0740-474a-a6fc-b537dbdf43f5"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 15,501,305\n",
            "Total tainable parameters: 15,501,305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yld0SPhi2HUm"
      },
      "source": [
        "Initialize model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JDmgtkGsav_",
        "outputId": "83f5ccc6-4a6a-43ec-f762-c1b82f3e3ff8"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "        nn.init.constant_(param.data, 0)   \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(8799, 256)\n",
              "    (gru): GRU(256, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(14073, 256)\n",
              "    (gru): GRU(512, 128)\n",
              "    (fc): Linear(in_features=640, out_features=14073, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1OnvuMKBIg_"
      },
      "source": [
        "### Optimizer and Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PowuX5bsasj"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX).to(device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpNeWJEJ2pcN"
      },
      "source": [
        "### Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVjp9XOsamS"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, src_len = batch.src\n",
        "        src = src.to(device)\n",
        "        src_len = src_len.to(device)\n",
        "        trg = batch.trg\n",
        "        trg = trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_len, trg)\n",
        "        \"\"\"\n",
        "        trg = [trg len, batch size]\n",
        "        output = [trg len, batch size, output dim]\n",
        "        \"\"\"\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \"\"\"\n",
        "        trg = [(trg len - 1) * batch size]\n",
        "        output = [(trg len - 1) * batch size, output dim]\n",
        "        \"\"\"\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for i, batch in enumerate(iterator):\n",
        "          src, src_len = batch.src\n",
        "          src = src.to(device)\n",
        "          src_len = src_len.to(device)\n",
        "          trg = batch.trg\n",
        "          trg = trg.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(src, src_len, trg, 0) ## Turn off the teacher forcing ratio.\n",
        "          \"\"\"\n",
        "          trg = [trg len, batch size]\n",
        "          output = [trg len, batch size, output dim]\n",
        "          \"\"\"\n",
        "          output_dim = output.shape[-1]\n",
        "          output = output[1:].view(-1, output_dim)\n",
        "          trg = trg[1:].view(-1)\n",
        "          \"\"\"\n",
        "          trg = [(trg len - 1) * batch size]\n",
        "          output = [(trg len - 1) * batch size, output dim]\n",
        "          \"\"\"\n",
        "          loss =  criterion(output, trg)\n",
        "          epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQG1RgUi2ujL"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z8_TXq8sadI"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def tabulate_training(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  table.align[column_names[2]] = 'r'\n",
        "  table.align[column_names[3]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhkS-JDd35qx"
      },
      "source": [
        "### Model Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCDVLXV39iK"
      },
      "source": [
        "MODEL_NAME = \"eng-po.pt\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shJMTRS7saRC",
        "outputId": "1605abdb-682b-4699-b6c6-d71c990ba127"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "column_names = [\"SET\", \"LOSS\", \"PPL\", \"ETA\"]\n",
        "print(\"TRAINING START....\")\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "  end = time.time()\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} | {'saving model...' if valid_loss < best_valid_loss else 'not saving...'}\" \n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), MODEL_NAME)\n",
        "  rows_data =[\n",
        "        [\"train\", f\"{train_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", hms_string(end - start) ],\n",
        "        [\"val\", f\"{valid_loss:.3f}\", f\"{math.exp(valid_loss):7.3f}\", '' ]\n",
        "  ]\n",
        "  tabulate_training(column_names, rows_data, title)\n",
        "\n",
        "print(\"TRAINING ENDS....\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING START....\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 01/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 4.099 |  60.297 | 0:04:19.49 |\n",
            "| val   | 3.376 |  29.249 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 02/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.338 |  10.356 | 0:04:19.11 |\n",
            "| val   | 2.575 |  13.128 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 03/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.740 |   5.695 | 0:04:19.43 |\n",
            "| val   | 2.362 |  10.617 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 04/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.481 |   4.395 | 0:04:19.54 |\n",
            "| val   | 2.234 |   9.341 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 05/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.333 |   3.794 | 0:04:18.97 |\n",
            "| val   | 2.137 |   8.478 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 06/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.228 |   3.415 | 0:04:17.36 |\n",
            "| val   | 2.170 |   8.758 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 07/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.152 |   3.164 | 0:04:17.18 |\n",
            "| val   | 2.126 |   8.380 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 08/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.096 |   2.992 | 0:04:16.47 |\n",
            "| val   | 2.146 |   8.555 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 09/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.061 |   2.890 | 0:04:16.84 |\n",
            "| val   | 2.156 |   8.638 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 10/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 1.034 |   2.812 | 0:04:16.87 |\n",
            "| val   | 2.170 |   8.757 |            |\n",
            "+-------+-------+---------+------------+\n",
            "TRAINING ENDS....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1_A2Nz5sKJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ab6c92-000a-4d25-b0a3-73c9b59cd750"
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_NAME))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{math.exp(test_loss):7.3f}', \"\"]]\n",
        "\n",
        "tabulate_training([\"SET\", \"LOSS\", \"PPL\", \"ETA\"], data_rows, title)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|   Model Evaluation Summary   |\n",
            "+------+-------+---------+-----+\n",
            "| SET  |  LOSS |     PPL | ETA |\n",
            "+------+-------+---------+-----+\n",
            "| Test | 2.044 |   7.721 |     |\n",
            "+------+-------+---------+-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J9H6zur4WU0"
      },
      "source": [
        "### Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duN_U05sBlkx"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPwMVJZ14Sxr"
      },
      "source": [
        "def translate_sentence(sent, src_field, trg_field, mdoel, device, max_len=50):\n",
        "  model.eval()\n",
        "\n",
        "  if isinstance(sent, str):\n",
        "    tokens = [token.text.lower() for token in nlp(sent)]\n",
        "  else:\n",
        "    tokens = [token.lower() for token in sent]\n",
        "  \n",
        "  tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "  src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "  src_len = torch.LongTensor([len(src_indexes)])\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "  mask = model.create_mask(src_tensor)\n",
        "  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "    with torch.no_grad():\n",
        "      output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "    attentions[i] = attention\n",
        "    pred_token = output.argmax(1).item()\n",
        "    trg_indexes.append(pred_token)\n",
        "\n",
        "    if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "       break\n",
        "  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "  return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqGmZM3q4uRG"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPjW60N4ve_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2acd56e-44f2-4cd0-80cd-393efcb71e2f"
      },
      "source": [
        "example_idx = 6\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['tom', 'did', \"n't\", 'notice', 'the', 'change', '.']\n",
            "trg = ['tom', 'não', 'percebeu', 'a', 'mudança', '.']\n",
            "predicted trg = ['tom', 'não', 'percebeu', 'a', 'mudança', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnwUFJB4B4Aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2970c40-9a29-422a-cf29-b0deefab7693"
      },
      "source": [
        "example_idx = 0\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "tokens, attention = translate_sentence(src,  SRC, TRG, model, device)\n",
        "print(f'pred = {tokens}')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['some', 'people', 'like', 'it', '.']\n",
            "trg = ['algumas', 'pessoas', 'gostam', '.']\n",
            "pred = ['algumas', 'pessoas', 'gostam', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IbwtKGXQRQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbb6f62-a609-417d-fd70-b8926f026fff"
      },
      "source": [
        "example_idx = 0\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "tokens, attention = translate_sentence(src,  SRC, TRG, model, device)\n",
        "print(f'pred = {tokens}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['tom', 'looks', 'relieved', '.']\n",
            "trg = ['tom', 'parece', 'aliviado', '.']\n",
            "pred = ['tom', 'parece', 'aliviado', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndxi8HR5QH_"
      },
      "source": [
        "Downloading the model name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47bvlKVO43k6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e426606-628c-401d-d54b-f812907abc35"
      },
      "source": [
        "files.download(MODEL_NAME)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d79e926d-4c72-4157-83e5-d6b319934556\", \"eng-po.pt\", 62009668)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_0KD0l1OM34"
      },
      "source": [
        "### BLEU SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qF2GsD85SM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13843303-0690-4cb7-e767-9f2e4fcd0d9b"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    for datum in data:\n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        # cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "\n",
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 45.92\n"
          ]
        }
      ]
    }
  ]
}