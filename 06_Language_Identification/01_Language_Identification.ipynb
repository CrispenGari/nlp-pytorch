{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Language_Identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0613j7QNvuev"
      },
      "source": [
        "### Language Identification using AI\n",
        "\n",
        "This is a notebook where we are going to train the model that will be able to detect languguages for our application. Basically we are going to use pytorch. I choose python over tensorflow because pytorch is my favorite this week.\n",
        "\n",
        "\n",
        "We are going to reference more notebooks that i've used before, but there are two notebooks that we will be using more. The notebooks are as follows:\n",
        "\n",
        "1. [01_Emotions_Sentiment_Analyisis_Packed_Padded_Sequences.ipynb](https://github.com/CrispenGari/nlp-pytorch/blob/main/03_Emotions/01_Emotions_Sentiment_Analyisis_Packed_Padded_Sequences.ipynb)\n",
        "\n",
        "2. [02_Duplicate_Questions_FastText.ipynb](https://github.com/CrispenGari/nlp-pytorch/blob/main/05_Duplicate_Questions/02_Duplicate_Questions_FastText.ipynb)\n",
        "\n",
        "I'm planning to use packed padded sequences based on the first referenced notebook but, because i care musch about speed, i will be using fast text, so most of the code will be taken from the second referenced notebook.\n",
        "\n",
        "The data that i will be working on will come from my google drive, I've aready preapared the data and we have `3` files:\n",
        "\n",
        "```py\n",
        "1. train.csv\n",
        "2. test.csv\n",
        "3. valid.csv\n",
        "\n",
        "## The langauges we will be identifying\n",
        "langanges = [\"eng\", \"fra\", \"deu\", \"ita\", \"swe\", \"por\", \"afr\"]\n",
        "```\n",
        "\n",
        "### Mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kYLaaP0vnWb",
        "outputId": "e69e6a5a-2723-4678-91a8-250d9ddaa5d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptmF_eHDx8-W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NWuceoCFvpIV",
        "outputId": "f339e472-14a0-49ff-a4ee-6af02c44a832"
      },
      "source": [
        "import time, os, torch, random, math\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK7AMTzuyLiu"
      },
      "source": [
        "We will be using torchtext\n",
        "\n",
        "\n",
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuknMRM2vpFL",
        "outputId": "ad95a2b7-b253-4aba-b430-e63263ead8da"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckenHm_yaxj"
      },
      "source": [
        "### Paths to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sa_e59kvpCf"
      },
      "source": [
        "base_path = '/content/drive/My Drive/NLP Data/lang-identification'\n",
        "train_path = 'train.csv'\n",
        "val_path = 'valid.csv'\n",
        "test_path = 'test.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1rsOCL0yhTj"
      },
      "source": [
        "### Generating `bigrams`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkzEAvWXvo_n",
        "outputId": "981965ae-0cb3-41ce-8787-2e363e80fccb"
      },
      "source": [
        "def generate_bigrams(x):\n",
        "  x = [i.lower() for i in x]\n",
        "  n_grams = set(zip(*[x[i: ] for i in range(2)]))\n",
        "  for n_gram in n_grams:\n",
        "      x.append(' '.join(n_gram))\n",
        "  return x\n",
        "generate_bigrams(['What', 'is', 'the', 'meaning', \"of\", \"OCR\", \"in\", \"python\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'ocr',\n",
              " 'in',\n",
              " 'python',\n",
              " 'what is',\n",
              " 'the meaning',\n",
              " 'ocr in',\n",
              " 'meaning of',\n",
              " 'is the',\n",
              " 'of ocr',\n",
              " 'in python']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJhsWGKy22g"
      },
      "source": [
        "### Tokenizer function\n",
        "\n",
        "I'm going to use my own tokenization function, this is because different languages has different tokenization language. I'm going to make this simple and tokenize the sentences using spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OefKcPxRzLtq"
      },
      "source": [
        "def tokenizer(sent):\n",
        "  return sent.split(\" \")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYpddZYWyo0H"
      },
      "source": [
        "### Creating the fields that will process our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ikYo17vo8p"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    tokenize = tokenizer,\n",
        "    preprocessing = generate_bigrams,\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiS4JRcMvo5u"
      },
      "source": [
        "fields = {\n",
        "    \"sent\": (\"text\", TEXT),\n",
        "    \"code\": (\"label\", LABEL),\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKwbXAcAz8f7"
      },
      "source": [
        "### Creating the dataset useing the `TabularDataset.split()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxJO5UsFvo3C"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   base_path,\n",
        "   train=train_path,\n",
        "   test= test_path,\n",
        "   validation= val_path,\n",
        "   format = \"csv\",\n",
        "   fields=fields\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmKyfK8Avoz-",
        "outputId": "5c5bdd7c-f04e-44f6-ce05-868f7ebdf9b6"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['it', 'is', 'absurd', 'of', 'you', 'to', 'do', 'that.', 'is absurd', 'it is', 'absurd of', 'of you', 'to do', 'do that.', 'you to'], 'label': 'eng'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ZKsVJF0LFm"
      },
      "source": [
        "### Building the vocabulary.\n",
        "\n",
        "We are not going to load the pretrained vocabulary since we have different languages and it does not make sense to do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNqKsUpevoxT"
      },
      "source": [
        "TEXT.build_vocab(\n",
        "    train_data\n",
        ")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F4Xcqw5voum",
        "outputId": "50e3c7cf-5f81-4727-875c-2bdb66eb26f7"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'afr': 6,\n",
              "             'deu': 3,\n",
              "             'eng': 0,\n",
              "             'fra': 2,\n",
              "             'ita': 4,\n",
              "             'por': 5,\n",
              "             'swe': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u8LYYJG1Qym"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Vg64Ui08EO"
      },
      "source": [
        "### Iterators\n",
        "\n",
        "We are going to make use of the `BucketIterator` to create iterators four our sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9rGhFt-vorv"
      },
      "source": [
        "sort_key = lambda x: len(x.text)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVNmlcsW1NPJ"
      },
      "source": [
        "### Next we will create a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-iP0D8vol2"
      },
      "source": [
        "class LanguageIndentifierFastText(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               output_dim,\n",
        "               pad_index,\n",
        "               dropout=.5\n",
        "               ):\n",
        "    super(LanguageIndentifierFastText, self).__init__()\n",
        "    self.embedding = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.out = nn.Linear(\n",
        "        embedding_size,\n",
        "        out_features = output_dim\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text).permute(1 ,0, 2)\n",
        "    pooled = F.avg_pool2d(embedded,(embedded.shape[1], 1)\n",
        "                          ).squeeze(1)\n",
        "    return self.out(pooled)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTsfJqk-1bhI"
      },
      "source": [
        "### Model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5N95nrvojR",
        "outputId": "8561a898-c037-47de-e405-f635c7f8b93a"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM =  len(LABEL.vocab)\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "language_identifier_model = LanguageIndentifierFastText(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            pad_index = PAD_IDX\n",
        "            ).to(device)\n",
        "language_identifier_model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageIndentifierFastText(\n",
              "  (embedding): Embedding(152163, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5cip7Bp2q0e"
      },
      "source": [
        "### Applying model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1QLBdv62tuH",
        "outputId": "c6d57391-737e-4aff-be20-ab1665134451"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "language_identifier_model.apply(init_weights)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageIndentifierFastText(\n",
              "  (embedding): Embedding(152163, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDyNCJ9U1fvk"
      },
      "source": [
        "### Counting model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqpGpLV5vogf",
        "outputId": "db38455f-67b8-4aa0-d094-3898ec6c9dbe"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(language_identifier_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 15,217,007\n",
            "Total tainable parameters: 15,217,007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX0LDyf822au"
      },
      "source": [
        "### Criterion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MtDquWBvod2"
      },
      "source": [
        "optimizer = torch.optim.Adam(language_identifier_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W98fkcPf3M0v"
      },
      "source": [
        "### Accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcIY4y4yvoa-"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MEOJ6f3Qxz"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.text\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCNXWj2-3VFH"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfmVwna13a3D"
      },
      "source": [
        "from prettytable import PrettyTable"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF6sq2Zy3USZ"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJNtP7Fl3Yfz",
        "outputId": "f3c9639a-6482-46bb-dafd-3bf16c87784e"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(language_identifier_model, \n",
        "                                  train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(language_identifier_model, \n",
        "                                     val_iter, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(language_identifier_model.state_dict(), 'best-lang-ident-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.483 |    0.788 | 0:00:03.06 |\n",
            "| Validation | 0.819 |    0.973 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.316 |    0.992 | 0:00:02.93 |\n",
            "| Validation | 0.267 |    0.986 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.086 |    0.997 | 0:00:02.95 |\n",
            "| Validation | 0.172 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.043 |    0.999 | 0:00:02.95 |\n",
            "| Validation | 0.135 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    1.000 | 0:00:02.95 |\n",
            "| Validation | 0.114 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.100 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.011 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.091 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.009 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.084 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.078 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 10/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.073 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.069 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 12/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.96 |\n",
            "| Validation | 0.066 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 13/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.063 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 14/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.061 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.058 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 16/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.056 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 17/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.98 |\n",
            "| Validation | 0.055 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 18/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.95 |\n",
            "| Validation | 0.053 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 19/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.052 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 20/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.051 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 21/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.050 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 22/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.049 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 23/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.047 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 24/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.047 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 25/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.96 |\n",
            "| Validation | 0.046 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 26/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.045 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 27/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.044 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 28/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.044 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 29/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.043 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 30/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.042 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 31/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.042 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 32/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.041 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 33/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.041 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 34/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 35/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 36/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 37/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.039 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 38/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.039 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 39/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.039 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 40/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.038 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 41/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.038 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 42/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.038 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 43/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.038 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 44/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.037 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 45/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.90 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 46/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 47/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.91 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 48/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 49/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 50/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 51/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.96 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 52/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.95 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 53/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.94 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 54/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.96 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 55/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.82 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 56/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.89 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 57/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 58/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.93 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 59/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.95 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 60/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.97 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 61/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 62/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.95 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 63/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.96 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 64/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.92 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 65/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.83 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 66/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 67/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 68/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 69/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 70/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 71/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 72/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 73/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.036 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 74/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.036 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 75/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.037 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 76/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.037 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 77/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.037 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 78/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.037 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 79/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.037 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 80/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.037 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 81/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 82/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 83/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 84/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.037 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 85/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.77 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 86/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 87/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 88/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.038 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 89/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.038 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 90/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.038 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 91/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.038 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 92/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.038 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 93/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.038 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 94/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.77 |\n",
            "| Validation | 0.039 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 95/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.039 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 96/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.039 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 97/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.80 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 98/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 99/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.81 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 100/100 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.79 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhSk9aXa4Ngh"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjX2cjQe3pmb",
        "outputId": "05115c57-2979-4671-f93f-90903ef7353e"
      },
      "source": [
        "language_identifier_model.load_state_dict(torch.load('best-lang-ident-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(language_identifier_model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.036 | Test Acc: 99.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbuhU7L4eRf"
      },
      "source": [
        "### Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwdpHygh5dUt",
        "outputId": "7ce1df69-6935-44c0-b1ce-2d42f15f5fd4"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'afr': 6,\n",
              "             'deu': 3,\n",
              "             'eng': 0,\n",
              "             'fra': 2,\n",
              "             'ita': 4,\n",
              "             'por': 5,\n",
              "             'swe': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idk_Ah4A6X24",
        "outputId": "e45c3a4c-8384-459a-fe3e-deb312871433"
      },
      "source": [
        "labels = {v:k for k, v in LABEL.vocab.stoi.items() }\n",
        "labels"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'eng', 1: 'swe', 2: 'fra', 3: 'deu', 4: 'ita', 5: 'por', 6: 'afr'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIq53QvI4ZCm",
        "outputId": "6c7834b7-6705-4547-eddd-56159f912688"
      },
      "source": [
        "def predict_language(model, sent):\n",
        "  model.eval()\n",
        "  sent = sent.lower()\n",
        "  tokenized = tokenizer(sent)\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  probabilities = torch.softmax(model(tensor), dim=1)\n",
        "  prediction = torch.argmax(probabilities, dim=1)\n",
        "  item = prediction.item()\n",
        "\n",
        "  return {\n",
        "      \"label\": item,\n",
        "      \"lang\": labels[item]\n",
        "  }\n",
        "\n",
        "predict_language(language_identifier_model, \"this\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0, 'lang': 'eng'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36i79I_d5Vrn",
        "outputId": "ec4bd503-7ebe-44e1-9906-51d791806296"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model, \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB3MkqhK7Acn",
        "outputId": "ca013aaa-fdce-461f-81be-decd499bf633"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCT4xZ3B7eru",
        "outputId": "4543ea17-e8a4-4ef7-a85c-0a17d91e0c18"
      },
      "source": [
        "# ita\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Si  fatto tagliare i capelli.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 4, 'lang': 'ita'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5-xsk707emd",
        "outputId": "d4a4bcee-b685-4b09-8fe7-a1ae426dcf57"
      },
      "source": [
        "# fra\n",
        "predict_language(language_identifier_model,\n",
        "                 \"J'ai peur de tomber.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2, 'lang': 'fra'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2r4DcKX7eju",
        "outputId": "5b30a132-5521-469f-a4a9-91186714fffa"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yu3HXd07ee7",
        "outputId": "004059b9-965f-47a8-d484-942a3413b725"
      },
      "source": [
        "# swe\n",
        "predict_language(language_identifier_model,\n",
        "                 \"ag skrev min frsta mening p tyska.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1, 'lang': 'swe'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsvB48fk7eb2",
        "outputId": "6d476bd0-32f7-4e6e-c9d1-a9b85e3dd541"
      },
      "source": [
        "# afr\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Ek gaan nie lank hier wees nie.\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 6, 'lang': 'afr'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIbJtRRU7eRO",
        "outputId": "839131d0-a875-47a4-8138-9c57daa1b128"
      },
      "source": [
        "# por\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Para mim no h problema algum.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 5, 'lang': 'por'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh1cKKFF7eN4"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}