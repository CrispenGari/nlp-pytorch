{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Language_Identification_Saving_Donloading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0613j7QNvuev"
      },
      "source": [
        "### Language Identification using AI\n",
        "\n",
        "This is a notebook where we are going to train the model that will be able to detect languguages for our application. Basically we are going to use pytorch. I choose python over tensorflow because pytorch is my favorite this week.\n",
        "\n",
        "\n",
        "We are going to reference more notebooks that i've used before, but there are two notebooks that we will be using more. The notebooks are as follows:\n",
        "\n",
        "1. [01_Emotions_Sentiment_Analyisis_Packed_Padded_Sequences.ipynb](https://github.com/CrispenGari/nlp-pytorch/blob/main/03_Emotions/01_Emotions_Sentiment_Analyisis_Packed_Padded_Sequences.ipynb)\n",
        "\n",
        "2. [02_Duplicate_Questions_FastText.ipynb](https://github.com/CrispenGari/nlp-pytorch/blob/main/05_Duplicate_Questions/02_Duplicate_Questions_FastText.ipynb)\n",
        "\n",
        "I'm planning to use packed padded sequences based on the first referenced notebook but, because i care musch about speed, i will be using fast text, so most of the code will be taken from the second referenced notebook.\n",
        "\n",
        "The data that i will be working on will come from my google drive, I've aready preapared the data and we have `3` files:\n",
        "\n",
        "```py\n",
        "1. train.csv\n",
        "2. test.csv\n",
        "3. valid.csv\n",
        "\n",
        "## The langauges we will be identifying\n",
        "langanges = [\"eng\", \"fra\", \"deu\", \"ita\", \"swe\", \"por\", \"afr\"]\n",
        "```\n",
        "\n",
        "### Mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kYLaaP0vnWb",
        "outputId": "2dc01b35-974c-440d-9a7c-60c422aa05b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptmF_eHDx8-W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NWuceoCFvpIV",
        "outputId": "a5a96465-202c-4c3b-cf9c-69760f9d0842"
      },
      "source": [
        "import time, os, torch, random, math, json\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK7AMTzuyLiu"
      },
      "source": [
        "We will be using torchtext\n",
        "\n",
        "\n",
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuknMRM2vpFL",
        "outputId": "17cb5656-ad69-4562-9bdd-8ea4b95fa896"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckenHm_yaxj"
      },
      "source": [
        "### Paths to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sa_e59kvpCf"
      },
      "source": [
        "base_path = '/content/drive/My Drive/NLP Data/lang-identification'\n",
        "train_path = 'train.csv'\n",
        "val_path = 'valid.csv'\n",
        "test_path = 'test.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1rsOCL0yhTj"
      },
      "source": [
        "### Generating `bigrams`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkzEAvWXvo_n",
        "outputId": "bcb10288-81ab-455b-9e54-83dcfaef1b11"
      },
      "source": [
        "def generate_bigrams(x):\n",
        "  x = [i.lower() for i in x]\n",
        "  n_grams = set(zip(*[x[i: ] for i in range(2)]))\n",
        "  for n_gram in n_grams:\n",
        "      x.append(' '.join(n_gram))\n",
        "  return x\n",
        "generate_bigrams(['What', 'is', 'the', 'meaning', \"of\", \"OCR\", \"in\", \"python\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'ocr',\n",
              " 'in',\n",
              " 'python',\n",
              " 'is the',\n",
              " 'ocr in',\n",
              " 'what is',\n",
              " 'the meaning',\n",
              " 'of ocr',\n",
              " 'meaning of',\n",
              " 'in python']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJhsWGKy22g"
      },
      "source": [
        "### Tokenizer function\n",
        "\n",
        "I'm going to use my own tokenization function, this is because different languages has different tokenization language. I'm going to make this simple and tokenize the sentences using spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OefKcPxRzLtq"
      },
      "source": [
        "def tokenizer(sent):\n",
        "  return sent.split(\" \")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYpddZYWyo0H"
      },
      "source": [
        "### Creating the fields that will process our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ikYo17vo8p"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    tokenize = tokenizer,\n",
        "    preprocessing = generate_bigrams,\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiS4JRcMvo5u"
      },
      "source": [
        "fields = {\n",
        "    \"sent\": (\"text\", TEXT),\n",
        "    \"code\": (\"label\", LABEL),\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKwbXAcAz8f7"
      },
      "source": [
        "### Creating the dataset useing the `TabularDataset.split()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxJO5UsFvo3C"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   base_path,\n",
        "   train=train_path,\n",
        "   test= test_path,\n",
        "   validation= val_path,\n",
        "   format = \"csv\",\n",
        "   fields=fields\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmKyfK8Avoz-",
        "outputId": "5a33905d-f1e9-4710-9772-e140f2beee77"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['it', 'is', 'absurd', 'of', 'you', 'to', 'do', 'that.', 'to do', 'it is', 'you to', 'is absurd', 'do that.', 'of you', 'absurd of'], 'label': 'eng'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ZKsVJF0LFm"
      },
      "source": [
        "### Building the vocabulary.\n",
        "\n",
        "We are not going to load the pretrained vocabulary since we have different languages and it does not make sense to do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNqKsUpevoxT"
      },
      "source": [
        "TEXT.build_vocab(\n",
        "    train_data\n",
        ")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F4Xcqw5voum",
        "outputId": "977fd471-f64a-44d5-d166-63ace8075833"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'afr': 6,\n",
              "             'deu': 3,\n",
              "             'eng': 0,\n",
              "             'fra': 2,\n",
              "             'ita': 4,\n",
              "             'por': 5,\n",
              "             'swe': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lggP_bOLik3d"
      },
      "source": [
        "### Saving the labels and words vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u8LYYJG1Qym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eceb68b-5250-4bcb-d850-8c27b801cb0a"
      },
      "source": [
        "words = dict(TEXT.vocab.stoi)\n",
        "labels = dict(LABEL.vocab.stoi)\n",
        "\n",
        "\n",
        "words_vocab_path = \"words_vocab.json\"\n",
        "labels_vocab_path = \"labels_vocab.json\"\n",
        "\n",
        "with open(words_vocab_path, \"w\") as f:\n",
        "  json.dump(words, f, indent=2)\n",
        "\n",
        "with open(labels_vocab_path, \"w\") as f:\n",
        "  json.dump(labels, f, indent=2)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NedxTa9YjQY8"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gT0GfgSlj6_T",
        "outputId": "0d8b79ca-e91e-4515-f14d-cb61b0566e40"
      },
      "source": [
        "files.download(labels_vocab_path)\n",
        "files.download(words_vocab_path)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f9fd88dc-403d-4e58-b296-c2f38b9c6e0a\", \"labels_vocab.json\", 86)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_04a70308-7266-4012-81a9-6111487b94aa\", \"words_vocab.json\", 3713476)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Vg64Ui08EO"
      },
      "source": [
        "### Iterators\n",
        "\n",
        "We are going to make use of the `BucketIterator` to create iterators four our sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9rGhFt-vorv"
      },
      "source": [
        "sort_key = lambda x: len(x.text)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVNmlcsW1NPJ"
      },
      "source": [
        "### Next we will create a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-iP0D8vol2"
      },
      "source": [
        "class LanguageIndentifierFastText(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               output_dim,\n",
        "               pad_index,\n",
        "               dropout=.5\n",
        "               ):\n",
        "    super(LanguageIndentifierFastText, self).__init__()\n",
        "    self.embedding = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.out = nn.Linear(\n",
        "        embedding_size,\n",
        "        out_features = output_dim\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text).permute(1 ,0, 2)\n",
        "    pooled = F.avg_pool2d(embedded,(embedded.shape[1], 1)\n",
        "                          ).squeeze(1)\n",
        "    return self.out(pooled)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTsfJqk-1bhI"
      },
      "source": [
        "### Model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5N95nrvojR",
        "outputId": "6effc75d-71ae-4d1f-a130-73cedf8cbc3d"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM =  len(LABEL.vocab)\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "language_identifier_model = LanguageIndentifierFastText(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            pad_index = PAD_IDX\n",
        "            ).to(device)\n",
        "language_identifier_model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageIndentifierFastText(\n",
              "  (embedding): Embedding(152163, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5cip7Bp2q0e"
      },
      "source": [
        "### Applying model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1QLBdv62tuH",
        "outputId": "dc3817bb-c0e2-4689-f2e6-637ef3421fc1"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "language_identifier_model.apply(init_weights)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageIndentifierFastText(\n",
              "  (embedding): Embedding(152163, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDyNCJ9U1fvk"
      },
      "source": [
        "### Counting model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqpGpLV5vogf",
        "outputId": "87d20257-ddc4-4b38-c1cb-5f769f9b2570"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(language_identifier_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 15,217,007\n",
            "Total tainable parameters: 15,217,007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX0LDyf822au"
      },
      "source": [
        "### Criterion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MtDquWBvod2"
      },
      "source": [
        "optimizer = torch.optim.Adam(language_identifier_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W98fkcPf3M0v"
      },
      "source": [
        "### Accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcIY4y4yvoa-"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MEOJ6f3Qxz"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.text\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCNXWj2-3VFH"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfmVwna13a3D"
      },
      "source": [
        "from prettytable import PrettyTable"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF6sq2Zy3USZ"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJNtP7Fl3Yfz",
        "outputId": "308eaf6b-bad4-4a34-ff8d-c52b5b343bb1"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(language_identifier_model, \n",
        "                                  train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(language_identifier_model, \n",
        "                                     val_iter, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(language_identifier_model.state_dict(), 'best-lang-ident-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.473 |    0.800 | 0:00:03.00 |\n",
            "| Validation | 0.810 |    0.971 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.315 |    0.992 | 0:00:02.72 |\n",
            "| Validation | 0.266 |    0.983 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.085 |    0.996 | 0:00:02.76 |\n",
            "| Validation | 0.171 |    0.986 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.042 |    0.998 | 0:00:02.73 |\n",
            "| Validation | 0.134 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.999 | 0:00:02.71 |\n",
            "| Validation | 0.112 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    1.000 | 0:00:03.10 |\n",
            "| Validation | 0.099 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    1.000 | 0:00:02.75 |\n",
            "| Validation | 0.089 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.082 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.077 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 10/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.072 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.068 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 12/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.065 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 13/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.062 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 14/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.70 |\n",
            "| Validation | 0.059 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.057 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 16/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.054 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 17/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.052 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 18/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.051 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 19/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.050 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 20/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.048 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 21/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.047 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 22/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.046 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 23/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.76 |\n",
            "| Validation | 0.045 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 24/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.044 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 25/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.043 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 26/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.043 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 27/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.75 |\n",
            "| Validation | 0.042 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 28/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.041 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 29/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.70 |\n",
            "| Validation | 0.041 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 30/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 31/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.040 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 32/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.039 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 33/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.76 |\n",
            "| Validation | 0.039 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 34/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.038 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 35/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.038 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 36/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 37/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.037 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 38/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.037 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 39/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.036 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 40/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.036 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 41/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.036 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 42/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.035 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 43/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 44/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 45/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 46/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 47/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 48/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.78 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 49/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.60 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 50/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 51/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 52/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 53/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.88 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 54/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.73 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 55/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 56/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.74 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 57/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.61 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 58/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 59/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.61 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 60/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.71 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 61/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.76 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 62/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.98 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 63/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.77 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 64/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.61 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 65/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 66/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.60 |\n",
            "| Validation | 0.033 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 67/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 68/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.69 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 69/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.72 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 70/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 71/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 72/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 73/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 74/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 75/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 76/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.034 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 77/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 78/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.60 |\n",
            "| Validation | 0.034 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 79/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.034 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 80/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.035 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 81/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.035 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 82/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.034 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 83/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.034 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 84/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 85/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 86/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.60 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 87/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 88/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 89/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 90/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 91/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.66 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 92/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.035 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 93/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 94/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.57 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 95/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 96/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 97/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.60 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 98/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.036 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 99/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.58 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 100/100 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:02.59 |\n",
            "| Validation | 0.037 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhSk9aXa4Ngh"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjX2cjQe3pmb",
        "outputId": "eb1b700a-c34d-4eac-b0db-4698626e79a2"
      },
      "source": [
        "language_identifier_model.load_state_dict(torch.load('best-lang-ident-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(language_identifier_model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.033 | Test Acc: 99.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbuhU7L4eRf"
      },
      "source": [
        "### Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwdpHygh5dUt",
        "outputId": "458ea230-7c77-4e39-cc2b-340b55ca3398"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'afr': 6,\n",
              "             'deu': 3,\n",
              "             'eng': 0,\n",
              "             'fra': 2,\n",
              "             'ita': 4,\n",
              "             'por': 5,\n",
              "             'swe': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idk_Ah4A6X24",
        "outputId": "dc0ea188-fe98-4f92-f03a-a1212535de99"
      },
      "source": [
        "labels = {v:k for k, v in LABEL.vocab.stoi.items() }\n",
        "labels"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'eng', 1: 'swe', 2: 'fra', 3: 'deu', 4: 'ita', 5: 'por', 6: 'afr'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIq53QvI4ZCm",
        "outputId": "744f653e-f302-40a4-d83a-d941b2b1cf25"
      },
      "source": [
        "def predict_language(model, sent):\n",
        "  model.eval()\n",
        "  sent = sent.lower()\n",
        "  tokenized = tokenizer(sent)\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  probabilities = torch.softmax(model(tensor), dim=1)\n",
        "  prediction = torch.argmax(probabilities, dim=1)\n",
        "  item = prediction.item()\n",
        "\n",
        "  return {\n",
        "      \"label\": item,\n",
        "      \"lang\": labels[item]\n",
        "  }\n",
        "\n",
        "predict_language(language_identifier_model, \"this\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0, 'lang': 'eng'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36i79I_d5Vrn",
        "outputId": "a9c017d3-7dd9-4057-d5d7-17d2395ccf0c"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model, \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB3MkqhK7Acn",
        "outputId": "62b06081-0e9f-4269-bd5a-07f01d8f6799"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCT4xZ3B7eru",
        "outputId": "f711fbea-ec34-4132-f8cb-4cd2926faab2"
      },
      "source": [
        "# ita\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Si  fatto tagliare i capelli.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 4, 'lang': 'ita'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5-xsk707emd",
        "outputId": "40f64cad-49c9-4cf0-b15a-ba6b60df9d51"
      },
      "source": [
        "# fra\n",
        "predict_language(language_identifier_model,\n",
        "                 \"J'ai peur de tomber.\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2, 'lang': 'fra'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2r4DcKX7eju",
        "outputId": "fc11b1e3-aada-467e-dd38-ffc025dc845e"
      },
      "source": [
        "# deu\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Herzlichen Glckwunsch zum Geburtstag, Muiriel!\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3, 'lang': 'deu'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yu3HXd07ee7",
        "outputId": "65259e56-ba94-4797-e8e0-e8055bde8889"
      },
      "source": [
        "# swe\n",
        "predict_language(language_identifier_model,\n",
        "                 \"ag skrev min frsta mening p tyska.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1, 'lang': 'swe'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsvB48fk7eb2",
        "outputId": "81ae7b6c-18df-40a9-ea0d-7f61b26765c2"
      },
      "source": [
        "# afr\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Ek gaan nie lank hier wees nie.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 6, 'lang': 'afr'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIbJtRRU7eRO",
        "outputId": "3839ab0d-f2a1-4dcd-dbf2-3152d56daeee"
      },
      "source": [
        "# por\n",
        "predict_language(language_identifier_model,\n",
        "                 \"Para mim no h problema algum.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 5, 'lang': 'por'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh1cKKFF7eN4"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANN8ZDvFltdg"
      },
      "source": [
        "### Donloading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TA4Pnl3jlvr5",
        "outputId": "6396f45e-7610-4318-f4c8-88e5a6332ca3"
      },
      "source": [
        "files.download(\"best-lang-ident-model.pt\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ae77147d-a2d7-4da3-800f-4d24851e23ec\", \"best-lang-ident-model.pt\", 60869347)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mApUFkKMl2gN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}